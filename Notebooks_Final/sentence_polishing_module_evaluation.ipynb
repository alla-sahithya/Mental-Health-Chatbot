{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f12b00a-cfd5-44c6-9951-e88e01b57603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da72de5d-8ec3-48de-8bf4-6a308adbd887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\surya\\anaconda3\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\surya\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch] -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ac22aa-d884-450e-bcc3-ab97f590b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4e27d2-0354-47ac-ab2d-00fc6b21b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s\\.,!?]', '', text)\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    clean_text = text.translate(str.maketrans(\"\", \"\", PUNCT_TO_REMOVE))\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c7c5ee-7067-4ff0-83d5-7940b12a6288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id                                          sentence1  \\\n",
      "0      swap_00001  Between 1962 and 1967 in Pennsylvania, annual ...   \n",
      "1      swap_00002  Martina Navratilova/Emilio Sánchez defeated Be...   \n",
      "2      swap_00003  Desdemona encounters Iago carrying buckets of ...   \n",
      "3      swap_00004  On 20 November 2010, Sergio got a chance to av...   \n",
      "4      swap_00005  There, the victory swung with every meter lost...   \n",
      "...           ...                                                ...   \n",
      "49995  swap_49996  At Waynesburg it collects a short stream known...   \n",
      "49996  swap_49997  In the books, Windsong's name is Go For the Bl...   \n",
      "49997  swap_49998  She then taught for a year in Balham before le...   \n",
      "49998  swap_49999  Acute mesenteric ischemia was first described ...   \n",
      "49999  swap_50000  Pajuveski is a village in Haljala Parish, Lään...   \n",
      "\n",
      "                                               sentence2  \n",
      "0      Between 1962 and 1967 in Pennsylvania, annual ...  \n",
      "1      Betsy Nagelsen/Paul Annacone defeated Martina ...  \n",
      "2      Iago encounters Desdemona carrying buckets of ...  \n",
      "3      On 20 November 2010, Williams got a chance to ...  \n",
      "4      There, the victory swung with every meter crea...  \n",
      "...                                                  ...  \n",
      "49995  At Little Sandy Creek it collects a short stre...  \n",
      "49996  In the books, Windsong's name is Go For the Bl...  \n",
      "49997  She then taught for a year in Battersea before...  \n",
      "49998  Chronic ischemia was first described in 1895 w...  \n",
      "49999  Pajuveski is a village in Estonia, Lääne-Viru ...  \n",
      "\n",
      "[50000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "\n",
    "data_frame = pd.read_csv('C:\\\\Users\\\\surya\\\\Downloads\\\\wiki_raw_and_mapping\\\\wiki_raw_and_mapping\\\\input_swap_wiki_50k.tsv', sep='\\t')\n",
    "\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a585efb-170d-44e2-bccc-0e5c520aa7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id  \\\n",
      "0      backtransl_set3_03491   \n",
      "1      backtransl_set3_04371   \n",
      "2      backtransl_set3_03621   \n",
      "3      backtransl_set3_04952   \n",
      "4      backtransl_set1_01157   \n",
      "...                      ...   \n",
      "26513  backtransl_set1_09460   \n",
      "26514  backtransl_set1_14350   \n",
      "26515  backtransl_set2_03959   \n",
      "26516  backtransl_set2_02524   \n",
      "26517  backtransl_set2_04849   \n",
      "\n",
      "                                               sentence1  \\\n",
      "0      He wrote the script in cooperation with Bianca...   \n",
      "1      He wrote the script in cooperation with Bianca...   \n",
      "2      He wrote the script in cooperation with Cyril ...   \n",
      "3      He wrote the script in cooperation with Cyril ...   \n",
      "4      Most Arabs in France are from the Maghreb but ...   \n",
      "...                                                  ...   \n",
      "26513  Abe Drexler (Charlie Hofheimer) calls Elisabet...   \n",
      "26514  Abe Drexler (Charlie Hofheimer) calls Elisabet...   \n",
      "26515  The Military ranks of Tajikistan are the milit...   \n",
      "26516  The military ranks of Tajikistan are the Milit...   \n",
      "26517  The military ranks of Tajikistan are the Milit...   \n",
      "\n",
      "                                               sentence2       swap_id  \n",
      "0      In collaboration with Bianca Olsen, Laurie Aub...  swap_00258_1  \n",
      "1      He wrote the script in collaboration with Bian...  swap_00258_1  \n",
      "2      He wrote the screenplay in cooperation with Cy...  swap_00258_2  \n",
      "3      In collaboration with Cyril Rambour, Laurie Au...  swap_00258_2  \n",
      "4      Most Arabs in France come from the Maghreb, bu...  swap_00334_1  \n",
      "...                                                  ...           ...  \n",
      "26513  Abe Drexler (Charlie Hofheimer) calls Elisabet...  swap_44707_2  \n",
      "26514  Abe Drexler (Charlie Hofheimer) calls Elisabet...  swap_44707_2  \n",
      "26515  The military ranks of Tajikistan are the milit...  swap_44980_1  \n",
      "26516  The military ranks of Tajikistan are the milit...  swap_44980_2  \n",
      "26517  The military ranks of Tajikistan are the milit...  swap_44980_2  \n",
      "\n",
      "[26518 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\surya\\\\Downloads\\\\wiki_raw_and_mapping\\\\wiki_raw_and_mapping\\\\input_backtransl_wiki_with_swap_id.tsv'\n",
    "\n",
    "def read_csv_handle_multiple_errors(file_path, sep='\\t'):\n",
    "    skip_rows = set()\n",
    "    while True:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=sep, skiprows=list(skip_rows))\n",
    "            break\n",
    "        except pd.errors.ParserError as e:\n",
    "            error_message = str(e)\n",
    "            try:\n",
    "                line_number = int(error_message.split('line')[1].split(',')[0]) - 1\n",
    "                if line_number in skip_rows:\n",
    "                    break\n",
    "                skip_rows.add(line_number)\n",
    "            except Exception as err:\n",
    "                print(\"An error occurred while parsing the error message:\", err)\n",
    "                break\n",
    "\n",
    "    return df\n",
    "data_frame1 = read_csv_handle_multiple_errors(file_path)\n",
    "\n",
    "print(data_frame1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df90534-a1ac-4a68-9e90-bfb1beb53a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           object\n",
      "sentence1    object\n",
      "sentence2    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_frame['id'] = data_frame['id'].astype(str)\n",
    "data_frame['sentence1'] = data_frame['sentence1'].astype(str)\n",
    "data_frame['sentence2'] = data_frame['sentence2'].astype(str)\n",
    "print(data_frame.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db2b193b-fc96-4a56-ab6b-38aaa6dc5e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           object\n",
      "sentence1    object\n",
      "sentence2    object\n",
      "swap_id      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_frame1['id'] = data_frame1['id'].astype(str)\n",
    "data_frame1['sentence1'] = data_frame1['sentence1'].astype(str)\n",
    "data_frame1['sentence2'] = data_frame1['sentence2'].astype(str)\n",
    "data_frame1['swap_id'] = data_frame1['swap_id'].astype(str)\n",
    "print(data_frame1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb22fb9-82c6-4275-ac70-af930f5e21a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 input  \\\n",
      "0    So I think we can not live if old people could...   \n",
      "1                                   For not use car .    \n",
      "2    Here was no promise of morning except that we ...   \n",
      "3    Thus even today sex is considered as the least...   \n",
      "4    image you salf you are wark in factory just to...   \n",
      "..                                                 ...   \n",
      "749  Other tourists would teach you some tips for t...   \n",
      "750  The government also should try to reduce the s...   \n",
      "751  Alot of memories with enogh time to remember w...   \n",
      "752           Sceene of violence can affect on them .    \n",
      "753  While the communities in general have reckoned...   \n",
      "\n",
      "                                                target  \n",
      "0    So I think we would not be alive if our ancest...  \n",
      "1                            Not for use with a car .   \n",
      "2    Here was no promise of morning , except that w...  \n",
      "3    Thus , even today , sex is considered as the l...  \n",
      "4    Imagine yourself you are working in factory ju...  \n",
      "..                                                 ...  \n",
      "749  Other tourists with experience can give you so...  \n",
      "750  The government should also try to reduce the s...  \n",
      "751  A lot of memories , with enough time to rememb...  \n",
      "752  A scene of violence can have an effect on them .   \n",
      "753  The communities in general have reckoned that ...  \n",
      "\n",
      "[754 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_frame2 = pd.read_csv('C:\\\\Users\\\\surya\\\\Downloads\\\\wiki_raw_and_mapping\\\\wiki_raw_and_mapping\\\\jfleg.csv')\n",
    "\n",
    "print(data_frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74877f08-846d-4ab1-a6a1-444778007714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input     object\n",
      "target    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_frame2['input'] = data_frame2['input'].astype(str)\n",
    "data_frame2['target'] = data_frame2['target'].astype(str)\n",
    "print(data_frame2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db486c45-5f5d-4786-8fd7-6e72d3037505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input     object\n",
       "target    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame2.columns\n",
    "data_frame2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e09fa68-eaaa-4e99-b7ed-20e31cb818a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\surya\\anaconda3\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\surya\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095e15ad-a412-4c05-8276-7ac4805515c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77272\n",
      "[{'input': 'between 1962 and 1967 in pennsylvania annual survival of breeding eastern towhees calculated from mistnetting recaptures was 58', 'target': 'between 1962 and 1967 in pennsylvania annual survival of breeding mistnetting towhees calculated from eastern recaptures was 58'}, {'input': 'martina navratilovaemilio sánchez defeated betsy nagelsenpaul annacone 6 4 6 7 7 6', 'target': 'betsy nagelsenpaul annacone defeated martina navratilovaemilio sánchez 6 4 6 7 7 6'}, {'input': 'desdemona encounters iago carrying buckets of filth and iago stirs jealousy in her', 'target': 'iago encounters desdemona carrying buckets of filth and iago stirs jealousy in her'}, {'input': 'on 20 november 2010 sergio got a chance to avenge his loss to williams', 'target': 'on 20 november 2010 williams got a chance to avenge his loss to sergio'}, {'input': 'there the victory swung with every meter lost or gained and where machetes and yataganes created a slaughter between both sides', 'target': 'there the victory swung with every meter created or gained and where machetes and yataganes lost a slaughter between both sides'}, {'input': 'la vegueta is a village in tinajo las palmas province of western lanzarote in the canary islands', 'target': 'la vegueta is a village in tinajo lanzarote province of western las palmas in the canary islands'}, {'input': 'it is found in the eastern andes of northwestern argentina and southern bolivia', 'target': 'it is found in the southern andes of northwestern argentina and eastern bolivia'}, {'input': 'razer punctured pussycats body and lifted it with the arm but pussycat fell and escaped', 'target': 'razer lifted pussycats body and punctured it with the arm but pussycat fell and escaped'}, {'input': 'corticons competitors include bosch software innovations fico ibmilog inrule technology openrules pegasystems red hat and others', 'target': 'pegasystemss competitors include bosch software innovations fico ibmilog inrule technology openrules corticon red hat and others'}, {'input': 'he was a lifelong friend of charles lutwidge dodgson lewis carroll and encouraged dodgson to take up photography', 'target': 'he was a lifelong friend of lewis carroll charles lutwidge dodgson and encouraged dodgson to take up photography'}]\n"
     ]
    }
   ],
   "source": [
    "formatted_data = []\n",
    "\n",
    "for index, row in data_frame.iterrows():\n",
    "    input_text = clean_text(row['sentence1'])\n",
    "    target_text = clean_text(row['sentence2'])\n",
    "    formatted_data.append({'input': input_text, 'target': target_text})\n",
    "\n",
    "for index, row in data_frame1.iterrows():\n",
    "    input_text = clean_text(row['sentence1'])\n",
    "    target_text = clean_text(row['sentence2'])\n",
    "    formatted_data.append({'input': input_text, 'target': target_text})\n",
    "\n",
    "for index, row in data_frame2.iterrows():\n",
    "    input_text = clean_text(row['input'])\n",
    "    target_text = clean_text(row['target'])\n",
    "    formatted_data.append({'input': input_text, 'target': target_text})\n",
    "\n",
    "print(len(formatted_data))\n",
    "print(formatted_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7721c81f-9392-4a55-a9c3-08405597a087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data stored in train_data.txt\n"
     ]
    }
   ],
   "source": [
    "formatted_data_out = pd.DataFrame(formatted_data)\n",
    "formatted_data_out.to_csv('C:\\\\Users\\\\surya\\\\Downloads\\\\wiki_raw_and_mapping\\\\wiki_raw_and_mapping\\\\train_data.txt', sep='\\t', index=False, header=True)\n",
    "print(\"Formatted data stored in train_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1901a1b5-f611-4060-a4f1-670e6bfb885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_dataset = {\n",
    "    \"input_text\": [pair[\"input\"] for pair in formatted_data],\n",
    "    \"output_text\": [pair[\"target\"] for pair in formatted_data]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a777b0de-e1a4-4d2d-8399-1b59d85a1459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained('kssumanth6/t5_small_sentence_polishing_generator_v3').to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained('kssumanth6/t5_small_sentence_polishing_generator_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4de0a80-fc2d-4624-81b6-65fdc973f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(talks):\n",
    "    tokenized_inputs = tokenizer(talks['input_text'], padding='max_length', truncation=True, max_length=256)\n",
    "    tokenized_outputs = tokenizer(talks['output_text'], padding='max_length', truncation=True, max_length=256)\n",
    "    return {'input_ids': tokenized_inputs['input_ids'], 'attention_mask': tokenized_inputs['attention_mask'], 'labels': tokenized_outputs['input_ids']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac16aa81-67b4-42d7-a3e0-a33659404850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7d888a194344eba4525fd8e3a8fd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict(formatted_dataset)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_eval_split = tokenized_datasets.train_test_split(test_size=0.2, shuffle=False)\n",
    "train_dataset = train_eval_split['train']\n",
    "eval_dataset = train_eval_split['test']\n",
    "\n",
    "val_test_split = eval_dataset.train_test_split(test_size = 0.5, shuffle=False)\n",
    "val_dataset = val_test_split['train']\n",
    "test_dataset = val_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15440d55-eb84-448a-8989-b4d7a8da6b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070c22e0-05d5-4e11-b85f-fe33bd814b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\surya\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\surya\\anaconda3\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: bert_score in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\surya\\anaconda3\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\surya\\anaconda3\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from bert_score) (2.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\surya\\anaconda3\\lib\\site-packages (from bert_score) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\surya\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: click in c:\\users\\surya\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\surya\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\surya\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\surya\\anaconda3\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\surya\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets sentencepiece transformers rouge_score bert_score huggingface_hub\n",
    "!pip install scikit-learn scipy matplotlib --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12e8809-4b0a-4c20-81a1-44059ff06c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\surya\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\surya\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\surya\\anaconda3\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: evaluate in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\surya\\anaconda3\\lib\\site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\surya\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\surya\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\surya\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: dill in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\surya\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\surya\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement bleurt (from versions: none)\n",
      "ERROR: No matching distribution found for bleurt\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge_score nltk absl-py transformers evaluate sentencepiece\n",
    "!pip3 install bleurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27c49509-463d-4797-932e-ffe5ae7cc7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in c:\\users\\surya\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: regex in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sacrebleu) (2023.10.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sacrebleu) (4.9.3)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\surya\\anaconda3\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\surya\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\surya\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\surya\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "909a2f7b-8afa-4637-8c0e-9c23c1fa7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.DataFrame(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c8d1f53-7eb3-4c7d-8e78-a4be21e8bfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he eventually made in the western republican o...</td>\n",
       "      <td>he finally made one of the first botanical col...</td>\n",
       "      <td>[3, 88, 3725, 263, 16, 8, 8282, 20237, 152, 80...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 88, 2031, 263, 80, 13, 8, 166, 28560, 8274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the longest surviving example in us is the thr...</td>\n",
       "      <td>the longest surviving example in the us is the...</td>\n",
       "      <td>[8, 14783, 3, 22279, 677, 16, 178, 19, 8, 386,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[8, 14783, 3, 22279, 677, 16, 8, 178, 19, 8, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gallagher feels betrayed and decides to join j...</td>\n",
       "      <td>gallagher feels deceived and decides to join j...</td>\n",
       "      <td>[12486, 18583, 49, 4227, 36, 1313, 10093, 11, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[12486, 18583, 49, 4227, 20, 565, 757, 26, 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joe feels betrayed and decides to join gallagh...</td>\n",
       "      <td>joe joe feels betrayed and decides to join gal...</td>\n",
       "      <td>[3, 1927, 15, 4227, 36, 1313, 10093, 11, 2204,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1927, 15, 3, 1927, 15, 4227, 36, 1313, 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>born in brockton massachusetts cariani was eig...</td>\n",
       "      <td>cariani was born in brockton massachusetts and...</td>\n",
       "      <td>[2170, 16, 3, 115, 6133, 17, 106, 3294, 1836, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[212, 5288, 23, 47, 2170, 16, 3, 115, 6133, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>born in presque isle maine cariani was eight w...</td>\n",
       "      <td>cariani was born in presque isle maine and eig...</td>\n",
       "      <td>[2170, 16, 15737, 19, 109, 711, 15, 212, 5288,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[212, 5288, 23, 47, 2170, 16, 15737, 19, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>born in presque isle maine cariani was eight w...</td>\n",
       "      <td>cariani was born in presque isle maine he was ...</td>\n",
       "      <td>[2170, 16, 15737, 19, 109, 711, 15, 212, 5288,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[212, 5288, 23, 47, 2170, 16, 15737, 19, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>christopher llewellyn born christopher griffit...</td>\n",
       "      <td>christopher llewellyn born christopher griffit...</td>\n",
       "      <td>[3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>christopher llewellyn born christopher griffit...</td>\n",
       "      <td>christopher llewellyn born christopher griffit...</td>\n",
       "      <td>[3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>christopher griffiths born christopher llewell...</td>\n",
       "      <td>christopher griffiths born christopher llewell...</td>\n",
       "      <td>[3, 15294, 10775, 49, 3, 11442, 23, 189, 7, 21...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 15294, 10775, 49, 3, 11442, 23, 189, 7, 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  he eventually made in the western republican o...   \n",
       "1  the longest surviving example in us is the thr...   \n",
       "2  gallagher feels betrayed and decides to join j...   \n",
       "3  joe feels betrayed and decides to join gallagh...   \n",
       "4  born in brockton massachusetts cariani was eig...   \n",
       "5  born in presque isle maine cariani was eight w...   \n",
       "6  born in presque isle maine cariani was eight w...   \n",
       "7  christopher llewellyn born christopher griffit...   \n",
       "8  christopher llewellyn born christopher griffit...   \n",
       "9  christopher griffiths born christopher llewell...   \n",
       "\n",
       "                                         output_text  \\\n",
       "0  he finally made one of the first botanical col...   \n",
       "1  the longest surviving example in the us is the...   \n",
       "2  gallagher feels deceived and decides to join j...   \n",
       "3  joe joe feels betrayed and decides to join gal...   \n",
       "4  cariani was born in brockton massachusetts and...   \n",
       "5  cariani was born in presque isle maine and eig...   \n",
       "6  cariani was born in presque isle maine he was ...   \n",
       "7  christopher llewellyn born christopher griffit...   \n",
       "8  christopher llewellyn born christopher griffit...   \n",
       "9  christopher griffiths born christopher llewell...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [3, 88, 3725, 263, 16, 8, 8282, 20237, 152, 80...   \n",
       "1  [8, 14783, 3, 22279, 677, 16, 178, 19, 8, 386,...   \n",
       "2  [12486, 18583, 49, 4227, 36, 1313, 10093, 11, ...   \n",
       "3  [3, 1927, 15, 4227, 36, 1313, 10093, 11, 2204,...   \n",
       "4  [2170, 16, 3, 115, 6133, 17, 106, 3294, 1836, ...   \n",
       "5  [2170, 16, 15737, 19, 109, 711, 15, 212, 5288,...   \n",
       "6  [2170, 16, 15737, 19, 109, 711, 15, 212, 5288,...   \n",
       "7  [3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...   \n",
       "8  [3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...   \n",
       "9  [3, 15294, 10775, 49, 3, 11442, 23, 189, 7, 21...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "8  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [3, 88, 2031, 263, 80, 13, 8, 166, 28560, 8274...  \n",
       "1  [8, 14783, 3, 22279, 677, 16, 8, 178, 19, 8, 3...  \n",
       "2  [12486, 18583, 49, 4227, 20, 565, 757, 26, 11,...  \n",
       "3  [3, 1927, 15, 3, 1927, 15, 4227, 36, 1313, 100...  \n",
       "4  [212, 5288, 23, 47, 2170, 16, 3, 115, 6133, 17...  \n",
       "5  [212, 5288, 23, 47, 2170, 16, 15737, 19, 109, ...  \n",
       "6  [212, 5288, 23, 47, 2170, 16, 15737, 19, 109, ...  \n",
       "7  [3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...  \n",
       "8  [3, 15294, 10775, 49, 3, 195, 15, 2091, 63, 29...  \n",
       "9  [3, 15294, 10775, 49, 3, 11442, 23, 189, 7, 21...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11821093-858a-4858-930e-59d74c25bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he eventually made in the western republican one of the first botanical collections published in ohio by a professional botanist\n",
      "he finally made one of the first botanical collections in the western republican which were published in ohio by a professional botanist\n",
      "the longest surviving example in us is the threespan mottville 12 st joseph river bridge built in 1922 in michigan\n",
      "the longest surviving example in the us is the threestage mottville 12 st joseph river bridge built in michigan in 1922\n",
      "gallagher feels betrayed and decides to join joes escape plan\n",
      "gallagher feels deceived and decides to join joes escape plan\n",
      "joe feels betrayed and decides to join gallaghers escape plan\n",
      "joe joe feels betrayed and decides to join gallaghers escape plan\n",
      "born in brockton massachusetts cariani was eight when his family moved to presque isle maine\n",
      "cariani was born in brockton massachusetts and eight years old when his family moved to presque isle maine\n",
      "born in presque isle maine cariani was eight when his family moved to brockton massachusetts\n",
      "cariani was born in presque isle maine and eight years old when his family moved to brockton massachusetts\n",
      "born in presque isle maine cariani was eight when his family moved to brockton massachusetts\n",
      "cariani was born in presque isle maine he was eight when his family moved to brockton massachusetts\n",
      "christopher llewellyn born christopher griffiths is an actor best known for his role as logan in the 2002 film where were we\n",
      "christopher llewellyn born christopher griffiths is an actor who became known for his role as a logan in the film where were we 2002\n",
      "christopher llewellyn born christopher griffiths is an actor best known for his role as logan in the 2002 film where were we\n",
      "christopher llewellyn born christopher griffiths is an actor known for his role as logan in the film where were we from the year 2002\n",
      "christopher griffiths born christopher llewellyn is an actor best known for his role as logan in the 2002 film where were we\n",
      "christopher griffiths born christopher llewellyn is an actor known for his role as logan in the film where were we from the year 2002\n"
     ]
    }
   ],
   "source": [
    "for index, row in test_dataset[0:10].iterrows():\n",
    "   input_text, label = row['input_text'], row['output_text']\n",
    "   print(input_text)\n",
    "   print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa1f988d-ec7c-4d1d-838b-cbbba98e4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt_text, model, tokenizer, device):\n",
    "\n",
    "    input_ids = tokenizer(prompt_text, return_tensors='pt', padding=\"max_length\", max_length=256, truncation=True)\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    outputs = model.generate(input_ids=input_ids['input_ids'], do_sample=True, max_length=300, num_beams=5, no_repeat_ngram_size=2)\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48f22588-fe6e-47ae-ba26-8bd52468ea2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7728"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05283ac2-a2df-40bc-bf82-4e59e9ca7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = []\n",
    "generated_sentences = []\n",
    "start = 0\n",
    "end = 50\n",
    "for index, row in test_dataset[start:end].iterrows():\n",
    "    input_text, label = row['input_text'], row['output_text']\n",
    "    generated_sentences.append(generate_text(input_text, model, tokenizer, device))\n",
    "    original_sentences.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e19eef7-b4f2-40d7-b826-8c555220e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he finally made one of the first botanical collections in the western republican which were published in ohio by a professional botanist\n",
      "he eventually made in the western republican one of the first botanical collections published in ohio by a professional botanist\n"
     ]
    }
   ],
   "source": [
    "print(original_sentences[0])\n",
    "print(generated_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88cb8f9b-680b-4001-a9c3-319a774f7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Hello\n"
     ]
    }
   ],
   "source": [
    "prompt_text = \"Hello\"\n",
    "generated_text = generate_text(prompt_text, model, tokenizer, device)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f96e41a-b992-42f0-852f-cac72254f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8639466134527458"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "original_tokenized = [sentence.split() for sentence in original_sentences]\n",
    "generated_tokenized = [sentence.split() for sentence in generated_sentences]\n",
    "\n",
    "bleu1_score = corpus_bleu([[ref] for ref in original_tokenized], generated_tokenized, weights=(1, 0, 0, 0))\n",
    "\n",
    "bleu1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4edee6b-917e-4987-b2c7-36574cec4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf39202d9f44be0b8a7b5cb551b7e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ff154c21584f619633509c1a89ba8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.78 seconds, 63.96 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9617509245872498"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(cands=generated_sentences, refs=original_sentences, lang=\"en\", verbose=True)\n",
    "\n",
    "F1.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41642e96-89e2-49ad-8608-28833ac48900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.8834174265111039,\n",
       " 'rouge2': 0.6714145477229065,\n",
       " 'rougeL': 0.7832440510097671,\n",
       " 'rougeLsum': 0.7846684298027697}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "rouge = load('rouge')\n",
    "\n",
    "rouge_score = rouge.compute(predictions=generated_sentences, references=original_sentences)\n",
    "\n",
    "rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6af92ca1-4f2f-4a82-af5f-6fb364686735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1538678407669067\n",
      "Perplexity: 3.1704320907592773\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_ids_original = tokenizer(original_sentences, padding=\"max_length\", max_length=256, return_tensors=\"pt\", truncation=True)\n",
    "input_ids_generated = tokenizer(generated_sentences, padding=\"max_length\", max_length=256, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_ids_original = input_ids_original.to(device)\n",
    "input_ids_generated = input_ids_generated.to(device)\n",
    "\n",
    "outputs = model(input_ids=input_ids_original[\"input_ids\"], labels=input_ids_generated[\"input_ids\"])\n",
    "loss = outputs.loss.item()\n",
    "\n",
    "perplexity = torch.exp(outputs.loss).item()\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
