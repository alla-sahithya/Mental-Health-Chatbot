{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-07T01:11:17.074427Z",
     "iopub.status.busy": "2024-05-07T01:11:17.073787Z",
     "iopub.status.idle": "2024-05-07T01:12:01.608011Z",
     "shell.execute_reply": "2024-05-07T01:12:01.606709Z",
     "shell.execute_reply.started": "2024-05-07T01:11:17.074390Z"
    },
    "id": "iycQm_djK78Q",
    "outputId": "e3766fbf-4655-497a-b38a-0224e1aff490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=2fbcdb125b2bc8f16cb9bf2b480dbc9d346b0dffec1ea4d8f85512e9b9f5a09c\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score, evaluate, bert_score\n",
      "Successfully installed bert_score-0.3.13 evaluate-0.4.2 rouge_score-0.1.2\n",
      "\u001b[31mERROR: Invalid requirement: '-'\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\n",
      "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.8.2 sacrebleu-2.4.2\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.29.3\n",
      "    Uninstalling accelerate-0.29.3:\n",
      "      Successfully uninstalled accelerate-0.29.3\n",
      "Successfully installed accelerate-0.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets sentencepiece transformers evaluate rouge_score bert_score huggingface_hub sentencepiece\n",
    "!pip install - U scikit-learn scipy matplotlib\n",
    "!pip install sacrebleu\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:01.610497Z",
     "iopub.status.busy": "2024-05-07T01:12:01.610153Z",
     "iopub.status.idle": "2024-05-07T01:12:19.499972Z",
     "shell.execute_reply": "2024-05-07T01:12:19.499146Z",
     "shell.execute_reply.started": "2024-05-07T01:12:01.610464Z"
    },
    "id": "xXii1PNNK-h3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import EncoderDecoderModel\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sacrebleu import corpus_bleu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:35.062141Z",
     "iopub.status.busy": "2024-05-07T01:12:35.061284Z",
     "iopub.status.idle": "2024-05-07T01:12:35.297204Z",
     "shell.execute_reply": "2024-05-07T01:12:35.296404Z",
     "shell.execute_reply.started": "2024-05-07T01:12:35.062106Z"
    },
    "id": "IlkxWrEYOmxD"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json('/kaggle/input/empathetic-dataset/train.json')\n",
    "test_df = pd.read_json('/kaggle/input/empathetic-dataset/test.json')\n",
    "val_df = pd.read_json('/kaggle/input/empathetic-dataset/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:37.277211Z",
     "iopub.status.busy": "2024-05-07T01:12:37.276837Z",
     "iopub.status.idle": "2024-05-07T01:12:37.304135Z",
     "shell.execute_reply": "2024-05-07T01:12:37.303067Z",
     "shell.execute_reply.started": "2024-05-07T01:12:37.277183Z"
    },
    "id": "K74Vgl0EPLES"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:39.281203Z",
     "iopub.status.busy": "2024-05-07T01:12:39.280872Z",
     "iopub.status.idle": "2024-05-07T01:12:43.272997Z",
     "shell.execute_reply": "2024-05-07T01:12:43.272085Z",
     "shell.execute_reply.started": "2024-05-07T01:12:39.281178Z"
    },
    "id": "uIopNrzKPQHt",
    "outputId": "99b13e30-526b-4c2f-b802-f5c281ab85cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2442838c4c4d798c3bceaf64fd5ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8971731300eb4436bdb3e587ba4bf933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af62fa89ebb84b96ac5457696122068e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f22077e99b4caf8e14011b8d6317c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d597beddbd4a63b04551a78a921689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd24860b27364d6689015ac3ecccb145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:45.866914Z",
     "iopub.status.busy": "2024-05-07T01:12:45.866080Z",
     "iopub.status.idle": "2024-05-07T01:12:45.871690Z",
     "shell.execute_reply": "2024-05-07T01:12:45.870766Z",
     "shell.execute_reply.started": "2024-05-07T01:12:45.866879Z"
    },
    "id": "T_48CFdjPWBP"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(df):\n",
    "    input = df['input'].tolist()\n",
    "    output = df['output'].tolist()\n",
    "    inputs = tokenizer(input, text_target=output, truncation=True, padding='max_length')\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:47.305905Z",
     "iopub.status.busy": "2024-05-07T01:12:47.304931Z",
     "iopub.status.idle": "2024-05-07T01:12:59.182871Z",
     "shell.execute_reply": "2024-05-07T01:12:59.181808Z",
     "shell.execute_reply.started": "2024-05-07T01:12:47.305862Z"
    },
    "id": "6Ve7dcmkQEwg"
   },
   "outputs": [],
   "source": [
    "train_tokenized_dataset = tokenize_function(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:12:59.189994Z",
     "iopub.status.busy": "2024-05-07T01:12:59.189636Z",
     "iopub.status.idle": "2024-05-07T01:13:01.553854Z",
     "shell.execute_reply": "2024-05-07T01:13:01.553036Z",
     "shell.execute_reply.started": "2024-05-07T01:12:59.189968Z"
    },
    "id": "4wfYHCBrQegD"
   },
   "outputs": [],
   "source": [
    "val_tokenized_dataset = tokenize_function(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:13:01.556018Z",
     "iopub.status.busy": "2024-05-07T01:13:01.555675Z",
     "iopub.status.idle": "2024-05-07T01:13:15.992296Z",
     "shell.execute_reply": "2024-05-07T01:13:15.991471Z",
     "shell.execute_reply.started": "2024-05-07T01:13:01.555993Z"
    },
    "id": "KBTwPhU0VYoy"
   },
   "outputs": [],
   "source": [
    "train_tokenized_dataset = Dataset.from_dict(train_tokenized_dataset)\n",
    "val_tokenized_dataset = Dataset.from_dict(val_tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:13:16.580423Z",
     "iopub.status.busy": "2024-05-07T01:13:16.580065Z",
     "iopub.status.idle": "2024-05-07T01:13:16.908001Z",
     "shell.execute_reply": "2024-05-07T01:13:16.906792Z",
     "shell.execute_reply.started": "2024-05-07T01:13:16.580395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:28:33.239540Z",
     "iopub.status.busy": "2024-05-07T01:28:33.238795Z",
     "iopub.status.idle": "2024-05-07T01:28:33.265561Z",
     "shell.execute_reply": "2024-05-07T01:28:33.264631Z",
     "shell.execute_reply.started": "2024-05-07T01:28:33.239504Z"
    },
    "id": "ziBAV6OPT0ze"
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./outputs',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=5,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:28:34.316924Z",
     "iopub.status.busy": "2024-05-07T01:28:34.316540Z",
     "iopub.status.idle": "2024-05-07T01:28:34.331278Z",
     "shell.execute_reply": "2024-05-07T01:28:34.330476Z",
     "shell.execute_reply.started": "2024-05-07T01:28:34.316896Z"
    },
    "id": "5_mBAhIQR-Io"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=val_tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "execution": {
     "iopub.execute_input": "2024-05-07T01:28:36.323208Z",
     "iopub.status.busy": "2024-05-07T01:28:36.322481Z",
     "iopub.status.idle": "2024-05-07T03:18:56.373472Z",
     "shell.execute_reply": "2024-05-07T03:18:56.372595Z",
     "shell.execute_reply.started": "2024-05-07T01:28:36.323176Z"
    },
    "id": "2v-obhsXUywt",
    "outputId": "93333de8-e578-4221-a306-176485314788"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9160' max='9160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9160/9160 1:50:18, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.194300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.096100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.093400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9160, training_loss=0.10855876280230727, metrics={'train_runtime': 6619.126, 'train_samples_per_second': 22.135, 'train_steps_per_second': 1.384, 'total_flos': 1.982973938447155e+16, 'train_loss': 0.10855876280230727, 'epoch': 4.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:18:56.375622Z",
     "iopub.status.busy": "2024-05-07T03:18:56.375306Z",
     "iopub.status.idle": "2024-05-07T03:20:28.569578Z",
     "shell.execute_reply": "2024-05-07T03:20:28.568803Z",
     "shell.execute_reply.started": "2024-05-07T03:18:56.375595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='357' max='357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [357/357 01:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:20:28.571073Z",
     "iopub.status.busy": "2024-05-07T03:20:28.570715Z",
     "iopub.status.idle": "2024-05-07T03:20:28.577594Z",
     "shell.execute_reply": "2024-05-07T03:20:28.576801Z",
     "shell.execute_reply.started": "2024-05-07T03:20:28.571041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09513427317142487,\n",
       " 'eval_runtime': 92.1882,\n",
       " 'eval_samples_per_second': 61.96,\n",
       " 'eval_steps_per_second': 3.873,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:21:20.217859Z",
     "iopub.status.busy": "2024-05-07T03:21:20.217415Z",
     "iopub.status.idle": "2024-05-07T03:21:20.245294Z",
     "shell.execute_reply": "2024-05-07T03:21:20.244436Z",
     "shell.execute_reply.started": "2024-05-07T03:21:20.217828Z"
    },
    "id": "tk0sYMlWU3wi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0fee57c1d9448cbcf1947e5ae2ccc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:21:33.851348Z",
     "iopub.status.busy": "2024-05-07T03:21:33.850725Z",
     "iopub.status.idle": "2024-05-07T03:21:46.675520Z",
     "shell.execute_reply": "2024-05-07T03:21:46.674598Z",
     "shell.execute_reply.started": "2024-05-07T03:21:33.851319Z"
    }
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"nlpproject/t5small_EmpatheticChatbot_ED2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:21:46.677407Z",
     "iopub.status.busy": "2024-05-07T03:21:46.677017Z",
     "iopub.status.idle": "2024-05-07T03:21:48.120592Z",
     "shell.execute_reply": "2024-05-07T03:21:48.119587Z",
     "shell.execute_reply.started": "2024-05-07T03:21:46.677367Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(\"nlpproject/t5small_EmpatheticChatbot_ED2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('intents.json') as f:\n",
    "#     data = json.load(f)\n",
    "# inputs, outputs = [], []\n",
    "# for intent in data['intents']:\n",
    "#     for pattern in intent['patterns']:\n",
    "#         for response in intent['responses']:\n",
    "#             inputs.append(pattern)\n",
    "#             outputs.append(response)\n",
    "# df = pd.DataFrame({'input': inputs, 'output': outputs})\n",
    "# df.to_csv('chat_data_for_t5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:21:48.122979Z",
     "iopub.status.busy": "2024-05-07T03:21:48.122579Z",
     "iopub.status.idle": "2024-05-07T03:22:04.572014Z",
     "shell.execute_reply": "2024-05-07T03:22:04.571089Z",
     "shell.execute_reply.started": "2024-05-07T03:21:48.122945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbdc56d47e8481cad8e2f8c8ccae2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be17bee7da334e52b8fb546179420254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bdc1427fa048b1bebb3bd3009c77d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7574194b1a4048e8a64297a007dd45ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b4bfded3414baca7718065e5230584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f3337fa8d346508ba17ffc1f4dad8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c477e2dbdc2747e98fba53a276453be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('nlpproject/t5small_EmpatheticChatbot_ED2', token='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')\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlpproject/t5small_EmpatheticChatbot_ED2', token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:22:35.698555Z",
     "iopub.status.busy": "2024-05-07T03:22:35.698116Z",
     "iopub.status.idle": "2024-05-07T03:22:35.725586Z",
     "shell.execute_reply": "2024-05-07T03:22:35.724823Z",
     "shell.execute_reply.started": "2024-05-07T03:22:35.698522Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('/kaggle/input/mental-health-convo/chat_data_for_t5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:29:53.388042Z",
     "iopub.status.busy": "2024-05-07T03:29:53.387657Z",
     "iopub.status.idle": "2024-05-07T03:29:53.394935Z",
     "shell.execute_reply": "2024-05-07T03:29:53.393975Z",
     "shell.execute_reply.started": "2024-05-07T03:29:53.388013Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:29:54.574392Z",
     "iopub.status.busy": "2024-05-07T03:29:54.573494Z",
     "iopub.status.idle": "2024-05-07T03:29:54.583549Z",
     "shell.execute_reply": "2024-05-07T03:29:54.582185Z",
     "shell.execute_reply.started": "2024-05-07T03:29:54.574356Z"
    }
   },
   "outputs": [],
   "source": [
    "formatted_data = dataset2.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:29:55.655672Z",
     "iopub.status.busy": "2024-05-07T03:29:55.654969Z",
     "iopub.status.idle": "2024-05-07T03:29:55.662075Z",
     "shell.execute_reply": "2024-05-07T03:29:55.661187Z",
     "shell.execute_reply.started": "2024-05-07T03:29:55.655623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'Hi', 'output': 'Hello there. Tell me how are you feeling today?'},\n",
       " {'input': 'Hi', 'output': 'Hi there. What brings you here today?'},\n",
       " {'input': 'Hi', 'output': 'Hi there. How are you feeling today?'},\n",
       " {'input': 'Hi', 'output': 'Great to see you. How do you feel currently?'},\n",
       " {'input': 'Hi',\n",
       "  'output': \"Hello there. Glad to see you're back. What's going on in your world right now?\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:29:56.697315Z",
     "iopub.status.busy": "2024-05-07T03:29:56.696910Z",
     "iopub.status.idle": "2024-05-07T03:29:56.702695Z",
     "shell.execute_reply": "2024-05-07T03:29:56.701688Z",
     "shell.execute_reply.started": "2024-05-07T03:29:56.697263Z"
    }
   },
   "outputs": [],
   "source": [
    "formatted_dataset = {\n",
    "    \"input\": [pair[\"input\"] for pair in formatted_data],\n",
    "    \"output\": [pair[\"output\"] for pair in formatted_data]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:29:58.061618Z",
     "iopub.status.busy": "2024-05-07T03:29:58.060744Z",
     "iopub.status.idle": "2024-05-07T03:29:58.073222Z",
     "shell.execute_reply": "2024-05-07T03:29:58.072232Z",
     "shell.execute_reply.started": "2024-05-07T03:29:58.061578Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_2 = Dataset.from_dict(formatted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:30:35.214627Z",
     "iopub.status.busy": "2024-05-07T03:30:35.214273Z",
     "iopub.status.idle": "2024-05-07T03:30:35.220526Z",
     "shell.execute_reply": "2024-05-07T03:30:35.219329Z",
     "shell.execute_reply.started": "2024-05-07T03:30:35.214598Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    tokenized_inputs = tokenizer(df['input'], padding='max_length', truncation=True, max_length=200)\n",
    "    tokenized_outputs = tokenizer(df['output'], padding='max_length', truncation=True, max_length=200)\n",
    "    return {'input_ids': tokenized_inputs['input_ids'], 'attention_mask': tokenized_inputs['attention_mask'], 'labels': tokenized_outputs['input_ids']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:31:03.711952Z",
     "iopub.status.busy": "2024-05-07T03:31:03.711551Z",
     "iopub.status.idle": "2024-05-07T03:31:03.921823Z",
     "shell.execute_reply": "2024-05-07T03:31:03.920856Z",
     "shell.execute_reply.started": "2024-05-07T03:31:03.711921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a3dd7548634d6db9379a3d73646828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/657 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset_2.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:31:32.795070Z",
     "iopub.status.busy": "2024-05-07T03:31:32.794108Z",
     "iopub.status.idle": "2024-05-07T03:31:32.810748Z",
     "shell.execute_reply": "2024-05-07T03:31:32.809738Z",
     "shell.execute_reply.started": "2024-05-07T03:31:32.795036Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:33:43.294468Z",
     "iopub.status.busy": "2024-05-07T03:33:43.293800Z",
     "iopub.status.idle": "2024-05-07T03:34:20.318784Z",
     "shell.execute_reply": "2024-05-07T03:34:20.317762Z",
     "shell.execute_reply.started": "2024-05-07T03:33:43.294437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [222/222 00:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.337393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=222, training_loss=0.2646562043610994, metrics={'train_runtime': 36.4173, 'train_samples_per_second': 48.686, 'train_steps_per_second': 6.096, 'total_flos': 93734771097600.0, 'train_loss': 0.2646562043610994, 'epoch': 3.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./output',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=8,   \n",
    "    per_device_eval_batch_size=8,    \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.001,               \n",
    "    logging_dir='./logs',            \n",
    "    save_strategy='epoch',           \n",
    "    evaluation_strategy='epoch',     \n",
    "    learning_rate=0.001,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:34:47.135820Z",
     "iopub.status.busy": "2024-05-07T03:34:47.135187Z",
     "iopub.status.idle": "2024-05-07T03:34:47.559854Z",
     "shell.execute_reply": "2024-05-07T03:34:47.558636Z",
     "shell.execute_reply.started": "2024-05-07T03:34:47.135787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results1 = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:34:53.884874Z",
     "iopub.status.busy": "2024-05-07T03:34:53.884532Z",
     "iopub.status.idle": "2024-05-07T03:34:53.890973Z",
     "shell.execute_reply": "2024-05-07T03:34:53.890067Z",
     "shell.execute_reply.started": "2024-05-07T03:34:53.884847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29084086418151855,\n",
       " 'eval_runtime': 0.4167,\n",
       " 'eval_samples_per_second': 158.398,\n",
       " 'eval_steps_per_second': 21.6,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:35:23.136023Z",
     "iopub.status.busy": "2024-05-07T03:35:23.135595Z",
     "iopub.status.idle": "2024-05-07T03:35:35.802108Z",
     "shell.execute_reply": "2024-05-07T03:35:35.801036Z",
     "shell.execute_reply.started": "2024-05-07T03:35:23.135989Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"nlpproject/t5small_EmpatheticChatbot_ED3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:35:35.804779Z",
     "iopub.status.busy": "2024-05-07T03:35:35.803921Z",
     "iopub.status.idle": "2024-05-07T03:35:38.066296Z",
     "shell.execute_reply": "2024-05-07T03:35:38.065224Z",
     "shell.execute_reply.started": "2024-05-07T03:35:35.804732Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(\"nlpproject/t5small_EmpatheticChatbot_ED3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:35:52.651879Z",
     "iopub.status.busy": "2024-05-07T03:35:52.651286Z",
     "iopub.status.idle": "2024-05-07T03:35:52.662567Z",
     "shell.execute_reply": "2024-05-07T03:35:52.661556Z",
     "shell.execute_reply.started": "2024-05-07T03:35:52.651847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:45:10.916640Z",
     "iopub.status.busy": "2024-05-07T03:45:10.916167Z",
     "iopub.status.idle": "2024-05-07T03:45:11.092632Z",
     "shell.execute_reply": "2024-05-07T03:45:11.091716Z",
     "shell.execute_reply.started": "2024-05-07T03:45:10.916602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: i'm sorry to hear that. if you want to talk about it.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt_text, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(prompt_text, return_tensors='pt')\n",
    "    outputs = model.generate(input_ids,\n",
    "                             min_length=3,\n",
    "                             max_length=50,\n",
    "                             do_sample=True,\n",
    "                             num_beams=2,\n",
    "                             no_repeat_ngram_size=2)\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "prompt_text = \"she doesn't like me\"\n",
    "generated_text = generate_response(prompt_text, model, tokenizer)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:41:07.396927Z",
     "iopub.status.busy": "2024-05-07T03:41:07.396546Z",
     "iopub.status.idle": "2024-05-07T03:41:27.413607Z",
     "shell.execute_reply": "2024-05-07T03:41:27.412460Z",
     "shell.execute_reply.started": "2024-05-07T03:41:07.396897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement bleurt (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for bleurt\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bleurt'...\n",
      "remote: Enumerating objects: 134, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 134 (delta 0), reused 17 (delta 0), pack-reused 116\u001b[K\n",
      "Receiving objects: 100% (134/134), 31.28 MiB | 21.38 MiB/s, done.\n",
      "Resolving deltas: 100% (49/49), done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement bleurt (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for bleurt\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge_score nltk absl-py transformers evaluate sentencepiece\n",
    "!pip3 install bleurt\n",
    "!git clone https://github.com/google-research/bleurt.git\n",
    "!pip install bleurt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:39:57.862759Z",
     "iopub.status.busy": "2024-05-07T03:39:57.862415Z",
     "iopub.status.idle": "2024-05-07T03:39:57.897438Z",
     "shell.execute_reply": "2024-05-07T03:39:57.896768Z",
     "shell.execute_reply.started": "2024-05-07T03:39:57.862730Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "import pandas as pd\n",
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(r'C:\\Users\\Sahithya Alla\\Desktop\\Spring 2024\\NLP\\milestone 3\\notebooks\\data\\empathetic\\test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:43:38.538107Z",
     "iopub.status.busy": "2024-05-07T03:43:38.537389Z",
     "iopub.status.idle": "2024-05-07T03:43:38.550153Z",
     "shell.execute_reply": "2024-05-07T03:43:38.549209Z",
     "shell.execute_reply.started": "2024-05-07T03:43:38.538072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yeah about 10 years ago I had a horrifying exp...</td>\n",
       "      <td>Did you suffer any injuries?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No I wasn't hit. It turned out they were drunk...</td>\n",
       "      <td>Why did you feel guilty? People really shouldn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got something nice the other day, chocolates...</td>\n",
       "      <td>Wow that must have been a surprise for you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was, and he does that type of thing a lot.</td>\n",
       "      <td>you got a great husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have problems with the city and their consta...</td>\n",
       "      <td>I know how you feel, it's terrible. I actually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>It probably will.</td>\n",
       "      <td>I can imagine. Maybe it'll morph into a Super ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>I borrowed a book from the library the other d...</td>\n",
       "      <td>That's a dang shame. Did it get rained on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>Yes it did, unfortunately</td>\n",
       "      <td>That's too bad. Well, on the bright side, mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>my husband lost a job but i'm hoping he can fi...</td>\n",
       "      <td>He will, I have faith.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>thank you so much!</td>\n",
       "      <td>No problem. What kind of work does he do?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     Yeah about 10 years ago I had a horrifying exp...   \n",
       "1     No I wasn't hit. It turned out they were drunk...   \n",
       "2     I got something nice the other day, chocolates...   \n",
       "3         It was, and he does that type of thing a lot.   \n",
       "4     I have problems with the city and their consta...   \n",
       "...                                                 ...   \n",
       "5237                                 It probably will.    \n",
       "5238  I borrowed a book from the library the other d...   \n",
       "5239                         Yes it did, unfortunately    \n",
       "5240  my husband lost a job but i'm hoping he can fi...   \n",
       "5241                                 thank you so much!   \n",
       "\n",
       "                                                 output  \n",
       "0                          Did you suffer any injuries?  \n",
       "1     Why did you feel guilty? People really shouldn...  \n",
       "2            Wow that must have been a surprise for you  \n",
       "3                               you got a great husband  \n",
       "4     I know how you feel, it's terrible. I actually...  \n",
       "...                                                 ...  \n",
       "5237  I can imagine. Maybe it'll morph into a Super ...  \n",
       "5238         That's a dang shame. Did it get rained on?  \n",
       "5239  That's too bad. Well, on the bright side, mayb...  \n",
       "5240                             He will, I have faith.  \n",
       "5241          No problem. What kind of work does he do?  \n",
       "\n",
       "[5242 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'nlpproject/t5small_EmpatheticChatbot_ED3'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T03:49:32.771124Z",
     "iopub.status.busy": "2024-05-07T03:49:32.770727Z",
     "iopub.status.idle": "2024-05-07T04:08:39.754959Z",
     "shell.execute_reply": "2024-05-07T04:08:39.754116Z",
     "shell.execute_reply.started": "2024-05-07T03:49:32.771078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "generated_output = []\n",
    "ground_truth =[]\n",
    "for index, row in test_df.iterrows():\n",
    "    response = generate_response(row['input'], model, tokenizer)\n",
    "    generated_output.append(response)\n",
    "    ground_truth.append(row['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:08:39.757098Z",
     "iopub.status.busy": "2024-05-07T04:08:39.756766Z",
     "iopub.status.idle": "2024-05-07T04:08:39.763063Z",
     "shell.execute_reply": "2024-05-07T04:08:39.762091Z",
     "shell.execute_reply.started": "2024-05-07T04:08:39.757057Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final_test = pd.DataFrame({'ground_truth': ground_truth, 'generated_output': generated_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:19:19.614582Z",
     "iopub.status.busy": "2024-05-07T04:19:19.613727Z",
     "iopub.status.idle": "2024-05-07T04:19:19.620556Z",
     "shell.execute_reply": "2024-05-07T04:19:19.619500Z",
     "shell.execute_reply.started": "2024-05-07T04:19:19.614542Z"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth = df_final_test['ground_truth'].tolist()\n",
    "generated_output = df_final_test['generated_output'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:10:12.543629Z",
     "iopub.status.busy": "2024-05-07T04:10:12.542911Z",
     "iopub.status.idle": "2024-05-07T04:10:12.584544Z",
     "shell.execute_reply": "2024-05-07T04:10:12.583836Z",
     "shell.execute_reply.started": "2024-05-07T04:10:12.543595Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_final_test.to_csv('testing_data_eg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:10:15.150620Z",
     "iopub.status.busy": "2024-05-07T04:10:15.149980Z",
     "iopub.status.idle": "2024-05-07T04:10:19.299457Z",
     "shell.execute_reply": "2024-05-07T04:10:19.298455Z",
     "shell.execute_reply.started": "2024-05-07T04:10:15.150587Z"
    }
   },
   "outputs": [],
   "source": [
    "bleu_score = evaluate.load(\"bleu\", module_type=\"metric\")\n",
    "bleu1 = bleu_score.compute(predictions=generated_output, references=ground_truth, max_order=1)\n",
    "bleu2 = bleu_score.compute(predictions=generated_output, references=ground_truth, max_order=2)\n",
    "bleu3 = bleu_score.compute(predictions=generated_output, references=ground_truth, max_order=3)\n",
    "bleu4 = bleu_score.compute(predictions=generated_output, references=ground_truth, max_order=4)\n",
    "print('BLEU 1', bleu1['bleu'])\n",
    "print('BLEU 2', bleu2['bleu'])\n",
    "print('BLEU 3', bleu3['bleu'])\n",
    "print('BLEU 4', bleu4['bleu'])\n",
    "print('Average BLEU score:', (bleu1['bleu'] + bleu2['bleu'] + bleu3['bleu'] + bleu4['bleu'])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:10:33.689768Z",
     "iopub.status.busy": "2024-05-07T04:10:33.688807Z",
     "iopub.status.idle": "2024-05-07T04:10:55.875359Z",
     "shell.execute_reply": "2024-05-07T04:10:55.874366Z",
     "shell.execute_reply.started": "2024-05-07T04:10:33.689722Z"
    }
   },
   "outputs": [],
   "source": [
    "precision, recall, f1 = score(generated_output, ground_truth, lang='en', verbose=False)\n",
    "print(f\"BERT score (F1): {f1.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:14:50.486923Z",
     "iopub.status.busy": "2024-05-07T04:14:50.486301Z",
     "iopub.status.idle": "2024-05-07T04:15:01.407275Z",
     "shell.execute_reply": "2024-05-07T04:15:01.406354Z",
     "shell.execute_reply.started": "2024-05-07T04:14:50.486888Z"
    }
   },
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "for i in range(len(ground_truth)):\n",
    "    reference_tokens = [ref.split() for ref in ground_truth[i]]\n",
    "    candidate_tokens = generated_output[i].split()\n",
    "    bleu_score = sentence_bleu(reference_tokens, candidate_tokens)\n",
    "    bleu_scores.append(bleu_score)\n",
    "print(sum(bleu_scores)/len(bleu_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:19:23.312674Z",
     "iopub.status.busy": "2024-05-07T04:19:23.311815Z",
     "iopub.status.idle": "2024-05-07T04:19:28.551058Z",
     "shell.execute_reply": "2024-05-07T04:19:28.549929Z",
     "shell.execute_reply.started": "2024-05-07T04:19:23.312616Z"
    }
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "rouge_score = rouge.compute(predictions=generated_output, references=ground_truth)\n",
    "rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:28:03.046922Z",
     "iopub.status.busy": "2024-05-07T04:28:03.045789Z",
     "iopub.status.idle": "2024-05-07T04:29:25.502971Z",
     "shell.execute_reply": "2024-05-07T04:29:25.502080Z",
     "shell.execute_reply.started": "2024-05-07T04:28:03.046882Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculating_t5_perplexity(input_text, target_text, model, tokenizer):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
    "    labels = tokenizer(target_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, labels=labels)\n",
    "        loss = output.loss\n",
    "    perplexity = torch.exp(loss)\n",
    "    return perplexity.item()\n",
    "\n",
    "perplexity_scores = []\n",
    "for ground_truth_x, generated_output_y in zip(ground_truth, generated_output):\n",
    "    perplexity = calculating_t5_perplexity(ground_truth_x, generated_output_y, model, tokenizer)\n",
    "    perplexity_scores.append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T04:30:37.330939Z",
     "iopub.status.busy": "2024-05-07T04:30:37.330087Z",
     "iopub.status.idle": "2024-05-07T04:30:37.335702Z",
     "shell.execute_reply": "2024-05-07T04:30:37.334612Z",
     "shell.execute_reply.started": "2024-05-07T04:30:37.330905Z"
    }
   },
   "outputs": [],
   "source": [
    "average_perplexity = sum(perplexity_scores) / len(perplexity_scores)\n",
    "print(\"Average Perplexity:\", average_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4953951,
     "sourceId": 8340821,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4954022,
     "sourceId": 8340921,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
